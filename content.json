{"pages":[{"title":"About","text":"","link":"/about/index.html"},{"title":"Categories","text":"","link":"/categories/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Python闭包和go闭包","text":"最近学习golang，发现golang里面也有闭包的概念，这里和python比较一下，并有些新的体会，记下来 1.Python 闭包闭包：引用了自由变量的函数，从下面这个例子看出，decorator的返回值_wrap引用了两个自由变量f和cache通过closure可以一探究竟，输出结果可以看出closure包含两个元素，一个是function，另外一个是cache， 123456789101112131415161718192021222324252627def decorator(f): cache = [] def _wrap(*args, **kwargs): cache.append(1) print(cache) f(*args, **kwargs) return _wrap# @decoratordef foo(): print(\"foo\")if __name__ == \"__main__\": a = decorator(foo) a() print(a.__closure__) print(a.__closure__[1].cell_contents) print(a.__closure__[0].cell_contents)# output#foo#(&lt;cell at 0x1094cd198: list object at 0x10acea248&gt;, &lt;cell at 0x1094cd4c8: function object at 0x107879268&gt;)#&lt;function foo at 0x107879268&gt;#[1] 之前写过一篇对于闭包中引用变量的生命周期，这次做了个实验，先看结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546def decorator(f): cache = [] def _wrap(*args, **kwargs): cache.append(1) print(cache) f(*args, **kwargs) return _wrap# @decoratordef foo(): print(\"foo\")if __name__ == \"__main__\": a = decorator(foo) a() a() print(a.__closure__) print(a.__closure__[1].cell_contents) print(a.__closure__[0].cell_contents) b = decorator(foo) b() b() print(b.__closure__) print(b.__closure__[1].cell_contents) print(b.__closure__[0].cell_contents)# output# [1]# foo# [1, 1]# foo# (&lt;cell at 0x10eb34198: list object at 0x11a657248&gt;, &lt;cell at 0x10eb344c8: function object at 0x10cee0268&gt;)# &lt;function foo at 0x10cee0268&gt;# [1, 1]# [1]# foo# [1, 1]# foo# (&lt;cell at 0x10eb34a98: list object at 0x112abb188&gt;, &lt;cell at 0x10eb34af8: function object at 0x10cee0268&gt;)# &lt;function foo at 0x10cee0268&gt;# [1, 1] 可以看到闭包的自由变量的作用域对于每个函数是独立的，即a和b对于f和cache的引用是独立的 2.Go闭包go的闭包和python基本一样，看个例子 123456789101112131415161718192021222324252627282930313233343536package mainimport \"fmt\"func decorator(f func()) func(){ var cache []string cache = append(cache, \"1\") _wrap := func() { cache = append(cache, \"foo\") fmt.Printf(\"%s\\n\", cache) f() } return _wrap}func foo() { fmt.Println(\"foo\")}func main() { a := decorator(foo) a() a() b := decorator(foo) b() b()}// output// [1 foo]// foo// [1 foo foo]// foo// [1 foo]// foo// [1 foo foo]//foo 可以看到对于a和b对于自用变量的引用也是独立的，互不影响","link":"/2019/03/22/decorator_2/"},{"title":"打包和工具链-《Go In Action》-Ch3","text":"3.1 包对于所有的.go文件，都应该在首行声明自己所属的包，每个包在一个单独的目录中，不能把多个包放在一个目录中，也不能把相同的包拆分到不同的目，同一个包下的所有.go文件必须声明同一个包名 包命名惯例，简洁，顾名思义 main包是特殊的包，编译程序会将带有main包声明的包编译为二进制可执行文件，main包中一定要有main函数，否则不可以创建可执行文件 3.2 导入导入包查找顺序 GOROOT -》 GOPATH，一旦编译器找到一个满足的包就会停止查找，也可以远程导入包，通过go get 将GitHub的包下载到本地 12345import ( \"fmt\" \"strings\" \"github.com/spf13/viper\") 如果包重名，可以使用命名导入，将导入的包命名为新名字 1234567891011package mainimport ( \"fmt\" myfmt \"mylib/fmt\")func main() { fmt.Println(\"Standard Library\") myfmt.Println(\"mylib/fmt\")} 如果导入了不在代码使用的包，会导致编译失败，可以使用下划线来重命名不适用的包 3.3 函数init每个包可以包含任意多个init函数，在main之前被调用，init函数用在设置包、初始化变量或者其他要在程序运行前优先完成的引导工作，可以使用下划线来重命名不适用的包以数据库驱动为例，sql包在编译时并不知道要注册哪些驱动，如果我们要使用数据库连接，就需要用init函数将驱动注册到mysql上 123456789package postgresimport ( \"database/sql\")func init() { sql.Register(\"postgres\", new(PostgresDriver))} 在使用这个新的数据库驱动时，需要使用空白标识符导入包12345678910package mainimport (\"database/sql\"_ \"github.com/goinaction/code/chapter3/dbdriver/postgres\")func main() {sql.Open(\"postgres\", \"mydb\")} 3.4 使用Go的工具go build 执行编译参数为空时 默认编译当前目录参数可以为文件名参数可以为/… 会编译目录下的所有包 go clean 执行清理，会删除可执行文件go run 先构建再执行 3.5 进一步介绍Go开发工具go vet 检测代码常见错误 printf类型匹配错误参数 方法签名错误 错误的结构标签 没有指定字段名的结构字面量go fmt 格式化代码go doc 打印文档godoc 浏览器打开文档 godoc -http:6000 3.7 依赖管理没有实际管理过一个大工程，这里看的稀里糊涂的，暂时不表了，等搞清楚再补 3.8 小结Go语言中包是组织代码的基本单位环境变量GOPATH决定了GO源代码在磁盘上被保存、编译和安装的位置可以为每个工程设置不同的GOPATH，以保持源代码和依赖的隔离go工具是在命令行上工作的最好工具开发人员可以使用go get获取别人的包并将其安装到自己的GOPATH指定的目录想要为别人创建包很见到，只要把源代码放到共有代码库，把那个遵守一些简单的规则就可以了GO语言在设计时将分享代码作为语言的核心特性和驱动力推荐使用依赖管理工具来管理依赖有很多社区开发的依赖管理工具，godep、vendor、gb","link":"/2019/04/12/go_pack_tool/"},{"title":"关于go语言的介绍-《Go In Action》-Ch1","text":"1.1 Go 解决现代编程的难题1.1.1 开发速度更加智能的编译器，简化依赖算法，编译速度更快，只会关注直接被引用的库编译器提供类型检查 1.1.2 并发提供并发支持，goroutine比线程更轻量级的并发，内置channel，在不同goroutine之间通信 1.goroutinegoroutine是可以和其他goroutine并行执行的函数，使用的内存更少。运行时会自动的配置一组逻辑处理器执行goroutine，每个逻辑处理器绑定到一个操作系统线程上，程序实行效率更高1234func log(msg string) { ....}go log(\"blablabla\") 2.channelchannel是可以让goroutine之间进行安全通信的工具，避免共享内存访问的问题，保证同一时刻只会有一个goroutine修改数据, 但是channel并不提供跨goroutine的数据访问保护机制，如果传输的是副本，那么每个goroutine都持有一个副本，各自对副本修改是安全的。但是如果传输的诗指针时，还是需要额外的同步动作 1.1.3 Go语言的类型系统无继承，使用组合设计模式，具有接口机制对行为进行建模 1. 类型简单内置简单类型，支持自定义类型，使用组合来支持扩展 2.Go接口对一组行为建模一个类型实现了一个接口的所有方法，那么这个类型的实例就可以存储在这个接口类型的实例中，不需要额外声明Go语言的整个网络库都是用了io.Reader接口，这样可以将程序的功能和不同的网络实现分离，任何实现了open方法的类型，都实现了io.Reader接口1234//io.Readertype Reader interface{ Read(p []byte) (n int, err error) } 1.1.3 内存管理Golang提供GC 1.2 Hello Go12345package mainimport \"fmt\"func main() { fmt.Println(\"Hello World\")} Go Playground是提供在线编辑运行Go的网站","link":"/2019/04/11/go_intro/"},{"title":"Python中的装饰器","text":"Python中的装饰器用的较为普遍，大致思路是在函数运行前后封装一些操作，以实现诸如如打印日志、统计运行时间、保存中间变量的效果。本文通过几个实例说明装饰器的基本用法和应用场景。 1.引子浏览网上各种解释装饰器的文章，提到最多的就是斐波那契数列的计算，这里先给出基础的计算斐波那契数列的函数： 12345def fib(n): if n &lt;= 2: return n - 1 else: return fib(n - 1) + fib(n - 2) 以上代码采用递归的方式计算第n个斐波那契数，其实这种递归计算方法会产生很多重复计算，我们将fib(5)的计算拆解开： 1234567 fib(5) / \\ fib(4) fib(3) / \\ / \\ fib(3) fib(2) fib(2) fib(1) / \\fib(2) fib(1) 从上面图中可以看到，fib(3)计算了2次，fib(2)计算了3次，fib(1)计算了2次，如果能将递归过程中的中间变量存储起来，就可以节省出很多时间，这里用装饰器的方法存储这些中间变量，首先给出代码： 12345678910111213141516171819def cache(f): cache_dict = {} @wraps(f) def _cache(n): if n in cache_dict.keys(): return cache_dict[n] else: cache_dict[n] = f(n) return cache_dict[n] return _cache@cachedef fib(n): if n &lt;= 2: return n - 1 else: return fib(n - 1) + fib(n - 2) 我们在装饰器中定义了一个全局的dict，用来存储第i个斐波那契值，每次计算fib(i)之前先去dict中查看是否已经缓存改值，如果缓存了直接从dict中取，否则计算fib(i)并写入dict中。 以上就实现了通过装饰器缓存部分变量，达到减少重复计算的目的，下面我们来了解一下装饰器的运行机制，以及变量的生命周期。 2.装饰器原理剖析从上面斐波那契数列的例子可以看到，装饰器其实是一个接受函数做参数，返回值为函数的函数。笼统的可以概括成以下的形式： 123456789101112def decorator(f): def _wrap(args): do somthing result = f(args) do somthing return result retun _wrap@decoratordef foo(args): do somthing 返回的函数其实包括了要运行的函数，并在函数运行前后做了若干操作。那当我们调用foo(args)到底发生了什么呢？ 当显示的调用foo(args)时，可以认为先执行了装饰器函数decorator(f)，装饰器函数返回了函数_wrap(args), 整体的调用顺序即是decorator(f)(args)，为了验证这个的结论，我们将上面斐波那契数列的例子修改一下，执行下面的语句： 123456print fib(20)print cache(fib)(20)#output41814181 可以看到两种输出方式结果是一致的， 从而验证了对于装饰器调用顺序的结论。为了更好的理解装饰器的调用顺序，这里对引子中的例子进行修改，再增加一层装饰器，如下： 12345678910111213141516171819202122232425262728293031323334def cache(f): cache_dict = {\"test\": \"foo\"} @wraps(f) def _cache(n): if n in cache_dict.keys(): return cache_dict[n] else: cache_dict[n] = f(n) return cache_dict[n] return _cachedef record(f): @wraps(f) def _wrap(n): start_time = time.time() result = f(n) end_time = time.time() logger.info('f_name:%s, n:%s, cost_time:%s', f.__name__, n, end_time - start_time) return result return _wrap@record@cachedef fib(n): if n &lt;= 2: return n - 1 else: return fib(n - 1) + fib(n - 2) 可以看到增加了record装饰器，作用是记录函数运行时间，先调用一下fib(20),看看结果: 123456782017-12-05 21:03:12,115 [140735241039872] - [decorate_learn.py 32] INFO n:2, cost_time:9.53674316406e-072017-12-05 21:03:12,115 [140735241039872] - [decorate_learn.py 32] INFO n:1, cost_time:3.09944152832e-062017-12-05 21:03:12,115 [140735241039872] - [decorate_learn.py 32] INFO n:3, cost_time:0.0004069805145262017-12-05 21:03:12,115 [140735241039872] - [decorate_learn.py 32] INFO n:2, cost_time:2.14576721191e-062017-12-05 21:03:12,116 [140735241039872] - [decorate_learn.py 32] INFO n:4, cost_time:0.0007228851318362017-12-05 21:03:12,116 [140735241039872] - [decorate_learn.py 32] INFO n:3, cost_time:3.09944152832e-062017-12-05 21:03:12,116 [140735241039872] - [decorate_learn.py 32] INFO n:5, cost_time:0.001335144042973 可以看到每次调用fib(n)函数的时间都被打印出来，如上面对装饰器调用顺序的结论，这里同样跑一下record(cache(fib))(5),得到如下结果： 1234567892017-12-05 21:09:35,869 [140735241039872] - [decorate_learn.py 32] INFO n:2, cost_time:2.86102294922e-062017-12-05 21:09:35,869 [140735241039872] - [decorate_learn.py 32] INFO n:1, cost_time:3.09944152832e-062017-12-05 21:09:35,869 [140735241039872] - [decorate_learn.py 32] INFO n:3, cost_time:0.0004301071166992017-12-05 21:09:35,869 [140735241039872] - [decorate_learn.py 32] INFO n:2, cost_time:1.90734863281e-062017-12-05 21:09:35,870 [140735241039872] - [decorate_learn.py 32] INFO n:4, cost_time:0.0006570816040042017-12-05 21:09:35,870 [140735241039872] - [decorate_learn.py 32] INFO n:3, cost_time:2.14576721191e-062017-12-05 21:09:35,870 [140735241039872] - [decorate_learn.py 32] INFO n:5, cost_time:0.000828027725222017-12-05 21:09:35,870 [140735241039872] - [decorate_learn.py 32] INFO n:5, cost_time:0.0009081363677983 以上研究了装饰器调用函数的流程，下面我们看下装饰器中变量的生命周期。注意到在斐波那契数列的例子中，定义了cache_dict字典，那该字典何时被创建，何时被销毁呢，为此我们做以下实验： 1234567891011import sysimport decorate_learnfor i in range(5): decorate_learn.fib(i + 1)reload(decorate_learn)for i in range(5): decorate_learn.fib(i + 1) 装饰器也稍作改变，每次调用的时候打印cache_dict12345678910111213def cache(f): cache_dict = {\"test\": \"foo\"} @wraps(f) def _cache(n): logger.info('n:%s,cache_dict:%s', n, cache_dict) if n in cache_dict.keys(): return cache_dict[n] else: cache_dict[n] = f(n) return cache_dict[n] return _cache 之所以这么做，是因为没有找到太好能够显示变量创建销毁的方法，所以每次调用装饰器的时候打印该变量，看下改变量的内容是否有被清空重建，看下输出日志： 123456789101112131415161718192021222017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:1,cache_dict:{&apos;test&apos;: &apos;foo&apos;}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:2,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:3,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:2,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:1,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:4,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:3,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:2,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:5,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1, 4: 2}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:4,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1, 4: 2}2017-12-06 09:45:07,733 [140735241039872] - [decorate_learn.py 16] INFO n:3,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1, 4: 2}2017-12-06 09:45:07,734 [140735241039872] - [decorate_learn.py 16] INFO n:1,cache_dict:{&apos;test&apos;: &apos;foo&apos;}2017-12-06 09:45:07,734 [140735241039872] - [decorate_learn.py 16] INFO n:2,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0}2017-12-06 09:45:07,735 [140735241039872] - [decorate_learn.py 16] INFO n:3,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1}2017-12-06 09:45:07,735 [140735241039872] - [decorate_learn.py 16] INFO n:2,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1}2017-12-06 09:45:07,735 [140735241039872] - [decorate_learn.py 16] INFO n:1,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1}2017-12-06 09:45:07,735 [140735241039872] - [decorate_learn.py 16] INFO n:4,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1}2017-12-06 09:45:07,736 [140735241039872] - [decorate_learn.py 16] INFO n:3,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1}2017-12-06 09:45:07,738 [140735241039872] - [decorate_learn.py 16] INFO n:2,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1}2017-12-06 09:45:07,738 [140735241039872] - [decorate_learn.py 16] INFO n:5,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1, 4: 2}2017-12-06 09:45:07,739 [140735241039872] - [decorate_learn.py 16] INFO n:4,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1, 4: 2}2017-12-06 09:45:07,739 [140735241039872] - [decorate_learn.py 16] INFO n:3,cache_dict:{&apos;test&apos;: &apos;foo&apos;, 1: 0, 2: 1, 3: 1, 4: 2} 从日志的输出可以看到，一次程序执行过程中，装饰器中dict是和fib函数同时存在的，只有当主程序退出时，dict才会销毁。以上我们研究了装饰器的写法和一些简单原理，下面给出一种使用类写装饰器的方法。 3.装饰器的另一种写法装饰器除了函数式的写法，还可以封装成类，并重写call方法即可，还是以菲波那切数列为例，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import timefrom functools import wrapsclass cache(object): def __init__(self): self.cache_dict = {} def __call__(self, f): @wraps(f) def _wrap(n): print self.cache_dict if n in self.cache_dict.keys(): return self.cache_dict[n] else: self.cache_dict[n] = f(n) return self.cache_dict[n] return _wrapclass record(object): def __init__(self): pass def __call__(self, f): @wraps(f) def _wrap(n): start_time = time.time() result = f(n) end_time = time.time() print 'f_name:%s, n:%s, cost_time:%s' % (f.__name__, n, end_time - start_time) return result return _wrap@record()@cache()def fib(n): if n &lt;= 2: return n - 1 else: return fib(n - 1) + fib(n - 2)@record()@cache()def foo(n): print \"foo\"# print fib(1)print fib(20)foo(1) 代码里需要解释的一点是我们引入了functools.wraps，目的是保持函数的类型一致。 12345678910111213#with wrapsfib(1)print fib.__name__#out#fib#without wrapsfib(1)print fib.__name__#out#_wrap 从上面可以看到，加了wrap可以让函数保持原有的名字 总结以上简单介绍了装饰器的实现方法和一些自己的小探究，笔而简之,以备阙忘。","link":"/2017/12/05/decorator/"},{"title":"生产者和消费者模型初探","text":"本文将尝试构造一个生产者，消费者模型，通过模型的构建，学习一下多线程编程。代码见：GitHub 1.生产者消费者模型关于生产者消费者模型的基本含义不在赘述。本实验的拟构造一个生产者，从文件中按行读取数据，放入队列中，构建十个消费者，从队列中读取数据，将数据写回文件。 1.1 starter首先我们构造一个方法，改方法负责初始化生产者和消费者线程 123456789101112131415161718192021222324252627public static void startMutiTheads(String inputPath, String outPath) { LocalDateTime startTime = LocalDateTime.now(); List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); LinkedBlockingQueue&lt;Optional&lt;String&gt;&gt; queue = new LinkedBlockingQueue&lt;&gt;(); FileUtil.clearFileContents(outPath); Producer producer = new Producer(inputPath, queue); threads.add(new Thread(producer)); Consumer consumer = new Consumer(outPath, queue); for(int i = 0; i &lt; Consumer.consumerThreadCount; i++){ Thread consumerThread = new Thread(consumer); threads.add(consumerThread); producer.addConsumer(consumer); } threads.forEach(Thread :: start); threads.forEach(thread -&gt; { try { thread.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); consumer.getFileUtil().flushAndClose(); // get consumer's totalCount: logger.debug(\"Consumer's totalCount: \" + consumer.getTotalCount()); LocalDateTime endTime = LocalDateTime.now(); logger.info(String.format(\"It takes %s seconds to finish\", LocalDateTime.from(startTime).until(endTime, ChronoUnit.SECONDS))); } 函数的有两个参数，分别表表示文件的输入路径和输出路径。下面我们构建一个thread列表，该列表存储所有的线程实例。 1LinkedBlockingQueue&lt;String&gt; queue = new LinkedBlockingQueue&lt;&gt;(); 我们选用concurrent包中的LinkedBlockingQueue队列，生产者线程将内从从文件读出放至该队列，消费者线程从改队列读出数据写回到文件。 LinkedBlockingQueue实现是线程安全的，实现了先进先出等特性，可以指定容量，也可以不指定，不指定的话，默认最大是Integer.MAX_VALUE，其中主要用到put和take方法，put方法在队列满的时候会阻塞直到有队列成员被消费，take方法在队列空的时候会阻塞，直到有队列成员被放进来。 下面我们构建了一个生产者线程，并放到theads列表中 12Producer producer = new Producer(inputPath, queue);threads.add(new Thread(producer)); 再之后构建十个消费者线程，其中Consumer.consumerThreadCount是在Counsmer中定义的一个静态变量，值为10 123456Consumer consumer = new Consumer(outPath, queue);for(int i = 0; i &lt; Consumer.consumerThreadCount; i++){ Thread consumerThread = new Thread(consumer); threads.add(consumerThread); producer.addConsumer(consumer); } 下面需要做的就是启动线程 12345678threads.forEach(Thread :: start);threads.forEach(thread -&gt; { try { thread.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); thread.join()方法会一直等待，直到改线程结束。 以上就是starter需要做的。 1.2 Produce本实验只设置了一个消费者模型，基本代码如下： 1234567891011121314151617public class Producer implements Runnable { private LinkedBlockingQueue&lt;Optional&lt;String&gt;&gt; queue; private String inputFile; public Producer(LinkedBlockingQueue&lt;Optional&lt;String&gt;&gt; queue, String inputFile) { this.queue = queue; this.inputFile = inputFile; } @Override public void run() { FileUtil.readFileLineByLine(inputFile, line -&gt; { queue.add(Optional.of(line)); }); for(int i = 0; i &lt; Consumer.consumerThreadCount; i++) { queue.add(Optional.empty()); } }} producer类只是简单的重载了Runable的run方法，run方法一开始，将文件内容读入到queue队列中，这里面用到了Java8里面lanmda表达式。 line -&gt; {queue.add(Optional.of(line)} FileUtil是一个文件读取工具类，readFileLineByLine将文件按行读出到queue中,这里面同样用到了Java8中的Consumer类，关于这个类暂时按下不表，可以理解为接收一个lanmda表达式，并对每个accept的参数进行lanmda表达式的操作： 123456789101112public static void readFileLineByLine(String filePath, Consumer&lt;String&gt; consumer) { try { BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(filePath), \"Cp1252\")); String line; while ((line = br.readLine()) != null) { consumer.accept(line); } br.close(); } catch(IOException e) { e.printStackTrace(); } } 后面的for循环是将十个Optional空对象放入queue中，这里做的目的是实现对Consumer线程的结束控制，具体原理会在Consumer类中进行表述。Optional是Java8的特性，其官方解释是： 这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象 较为通俗的说法是： 如果你开发过Java程序，可能会有过这样的经历：调用某种数据结构的一个方法得到了返回值却不能直接将返回值作为参数去调用别的方法。而是首先判断这个返回值是否为null，只有在非空的前提下才能将其作为其他方法的参数。Java8中新加了Optional这个类正是为了解决这个问题。 其具体用法以后解释，在本文中可简单理解为，在生产者将所有数据都写进队列后，我们放置10个空元素进入队列，消费者可根据空元素进行停止判断。 1.3 ConsumerConsumer的构建也是比较简单， 同producer一样，继承Runable，并重写Run方法： 123456789101112131415161718192021222324252627282930313233public class Consumer implements Runnable { private AtomicInteger totalCount = new AtomicInteger(0); public static final int consumerThreadCount = 10; private FileUtil fileUtil; private final static Logger logger = Logger.getLogger(Consumer.class); private LinkedBlockingQueue&lt;Optional&lt;String&gt;&gt; queue; public Consumer(LinkedBlockingQueue&lt;Optional&lt;String&gt;&gt; queue, String outputFile) { this.queue = queue; this.fileUtil = new FileUtil(outputFile); } @Override public void run() { try { while (true) { Optional&lt;String&gt; line = queue.take(); if (!line.isPresent()) break; totalCount.incrementAndGet(); String processedLine = fileUtil.processLine(line.get()); fileUtil.appendToFile(processedLine); } } catch (InterruptedException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } public FileUtil getFileUtil() { return fileUtil; } public int getTotalCount() { return totalCount.get(); }} 主要看一下run方法，run方法使用while循环，循环读取queue中的数据。上文介绍过，queue.take()方法会一直阻塞直到队列中塞进数据。此外run方法中有使用fileUtil的processLine方法： 1234567891011121314public String processLine(String line) throws IOException { int min = 1; int max = 100; int randomMillisecconds = min + (int)(Math.random() * ((max - min) + 1)); try { Thread.sleep(randomMillisecconds); } catch (InterruptedException e) { e.printStackTrace(); } // readLineCount is not accurate in multi-thread mode readLineCount++; logger.info(String.format(\"%d lines were read.\", readLineCount)); return line; } processLine主要是对Consumer读取的行数记性计数，并在log中打印出来。为什么这样做，未在测试实验时说明。关于Consumer还有一点需要关注，我们看到Consumer的run方法体中是一个while循环，那Consumer线程什么时候会停止就变成了一个问题\u0010。按照我们设计初衷，Producer把所有的文件按行读取到queue中，Consumer回去queue中读取数据，写回到另一个文件。按照这种逻辑，如果producer读完了所有文件，Consumer也将queue中的所有数据写回文件，此时Consumer就应该停止了。 1if (!line.isPresent()) break; 这段代码就是负责停止Consumer线程的。记得我们在Producer,当所有数据都读取到queue中时，会在queue中塞入十个optional.empty变量，那如果在Consumer中queue.take()返回的是optinal.empty，就说明queue已经无数据了，当前Consumer就可以停止了。关于如何在循环中停止线程，还有很多方法，待后面有时间再做解析。以上就是Consumer类的构造。 2.实验实验代码： 12345@Test public void multiThreadTest() throws IOException { starter.startMultiThreadTask(inputFile, outputFile); Assert.assertTrue(isFileDataSame(inputFile, outputFile)); } 实验结果,实验结果会打印总耗时以及两个count变量： 12345672017-03-01 13:52:04 INFO FileUtil:118 - 2954 lines were read.2017-03-01 13:52:04 INFO FileUtil:118 - 2955 lines were read.2017-03-01 13:52:04 INFO FileUtil:118 - 2956 lines were read.2017-03-01 13:52:04 INFO FileUtil:118 - 2957 lines were read.2017-03-01 13:52:04 INFO FileUtil:118 - 2958 lines were read.2017-03-01 13:52:04 DEBUG Starter:50 - Consumer&apos;s totalCount: 30002017-03-01 13:52:04 INFO Starter:53 - It takes 16 seconds to finish 解释一下，诸如2958 lines were read，是从FileUtil工具类processLine函数中打印出的readLine变量，其代表意义是线程Consumer线程从queue中读取了多少行。Consumer’s totalCount: 3000 是直接打印的Consumer全局变totalCount，其代表意义同样是十个线程总共从queue中读取了多少行，按道理来说，这两个值是应该相同的，然后结果明显不一致。 从代码我们可以看到readLine是一个int型变量，而totalCount是一个AtomicInteger变量，很显然问题出在了这里。我们知道Java中++这种操作是线程不安全的，而readLineCount是个全局变量，所以如果多个线程同事在执行++操作时，就会产生totalCount的值不一致的问题，解决方法可以粗暴的在processLine中加上synchronized关键字： 12345678910111213141516public String processLine(String line) throws IOException { synchronized (this) { int min = 1; int max = 100; int randomMillisecconds = min + (int) (Math.random() * ((max - min) + 1)); try { Thread.sleep(randomMillisecconds); } catch (InterruptedException e) { e.printStackTrace(); } // readLineCount is not accurate in multi-thread mode readLineCount++; logger.info(String.format(\"%d lines were read.\", readLineCount)); return line; } } 我们再次运行测试脚本： 1234567892017-03-01 14:09:34 INFO FileUtil:119 - 2994 lines were read.2017-03-01 14:09:34 INFO FileUtil:119 - 2995 lines were read.2017-03-01 14:09:34 INFO FileUtil:119 - 2996 lines were read.2017-03-01 14:09:34 INFO FileUtil:119 - 2997 lines were read.2017-03-01 14:09:35 INFO FileUtil:119 - 2998 lines were read.2017-03-01 14:09:35 INFO FileUtil:119 - 2999 lines were read.2017-03-01 14:09:35 INFO FileUtil:119 - 3000 lines were read.2017-03-01 14:09:35 DEBUG Starter:50 - Consumer&apos;s totalCount: 30002017-03-01 14:09:35 INFO Starter:53 - It takes 160 seconds to finish 可以看到两个变量的值相等了，说明这种方法可行，但是花费的时间确从16s到了160s，说明synchronized关键字极大的增加了时间的消耗，我们分析processLine方法，其实问题只出在readLineCount上，concurrent包中提供了AtomicInteger变量，它实现了对int变量的封装，实现了对自增操作的原子性。为此我们将readLineCount定义为： 1private AtomicInteger readLineCount = new AtomicInteger(0); processLine函数变为： 1234567891011121314public String processLine(String line) throws IOException { int min = 1; int max = 100; int randomMillisecconds = min + (int) (Math.random() * ((max - min) + 1)); try { Thread.sleep(randomMillisecconds); } catch (InterruptedException e) { e.printStackTrace(); } // readLineCount is not accurate in multi-thread mode readLineCount.incrementAndGet(); logger.info(String.format(\"%d lines were read.\", readLineCount.get())); return line; } 再次运行测试代码： 1234567892017-03-01 14:18:23 INFO FileUtil:120 - 2994 lines were read.2017-03-01 14:18:23 INFO FileUtil:120 - 2995 lines were read.2017-03-01 14:18:23 INFO FileUtil:120 - 2996 lines were read.2017-03-01 14:18:23 INFO FileUtil:120 - 2997 lines were read.2017-03-01 14:18:23 INFO FileUtil:120 - 2998 lines were read.2017-03-01 14:18:23 INFO FileUtil:120 - 2999 lines were read.2017-03-01 14:18:23 INFO FileUtil:120 - 3000 lines were read.2017-03-01 14:18:23 DEBUG Starter:50 - Consumer&apos;s totalCount: 30002017-03-01 14:18:23 INFO Starter:53 - It takes 15 seconds to finish 可以看到，两个变量值相等了，然后耗时只用了15s。从以上实验可以看到使用concurrent包中的变量和方法，比简单粗暴的使用synchronized这种方法在耗时方便具有很大的优势。 3.总结以上我们初步试验了一个简单的生产者消费者模型，使用了Cocurrent包中的一些方法。时间比较急，先写这么多，后续有内容再行添加。","link":"/2017/12/04/proandconsu/"},{"title":"快速开始一个GO程序-《Go In Action》-Ch2","text":"一上来接来个大程序，新手能接得住么这个程序从不同的数据源拉取数据，将数据内容与一组搜索项做对比，然后将匹配的内容显示在终端窗口。这个程序会读取文本文件，进行网络调用，解码XML 和JSON 成为结构化类型数据，并且利用Go 语言的并发机制保证这些操作的速度source code 2.1 程序架构1234567891011- sample - data data.json -- 包含一组数据源 - matchers rss.go -- 搜索 rss 源的匹配器 - search default.go -- 搜索数据用的默认匹配器 feed.go -- 用于读取 json 数据文件 match.go -- 用于支持不同匹配器的接口 search.go -- 执行搜索的主控制逻辑 main.go -- 程序的入口 2.2 main 包123456789101112131415161718192021package mainimport ( \"log\" \"os\" _ \"github.com/goinaction/code/chapter2/sample/matchers\" \"github.com/goinaction/code/chapter2/sample/search\")// init is called prior to main.func init() { // Change the device for logging to stdout. log.SetOutput(os.Stdout)}// main is the entry point for the program.func main() { // Perform the search for the specified term. search.Run(\"president\")} 有以下几点需要注意： main()是程序的入口，没有main函数，构建程序不会生成可执行文件 一个包定义一组编译通过的代码，包的名字类似命名空间，可以用来直接访问包内生命的标识符， 可以报不同包中定义的同名标识符区别开 下划线开头的包，是为了进行包的初始化操作，GO不允许声明导入包却不使用，下划线让编译器接受这种到日，并且调用对应包内所有文件代码里定义的init函数，init函数的执行在main函数之前 2.3 search 包serach 包包含了程序使用的框架和业务逻辑 2.3.1 serach.goserach文件先获取数据源，然后对每个数据源获取的数据进行匹配，每一个匹配启用一个goroutine。使用sync.WaitGroup控制任务是否完成。sync.WaitGroup是一个计数信号量，主要有三个方法Add、Done和Wait，每增加一个任务就Add一次，每完成一个任务就Done一次，调用Wait的时候程序会阻塞，直到所有任务完成。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package search//从标准库导入代码时，只需要给出要导入包的包名，//编译器查找包时，总是会到GOROOT和GOPATH环境变量引用的位置去查找import ( \"log\" \"sync\")// A map of registered matchers for searching.// 小写字母标识，标识包内变量，不导出 or 不公开var matchers = make(map[string]Matcher)// Run performs the search logic.func Run(searchTerm string) { // Retrieve the list of feeds to search through. feeds, err := RetrieveFeeds() if err != nil { log.Fatal(err) } // Create an unbuffered channel to receive match results to display. results := make(chan *Result) // Setup a wait group so we can process all the feeds. var waitGroup sync.WaitGroup // Set the number of goroutines we need to wait for while // they process the individual feeds. waitGroup.Add(len(feeds)) // Launch a goroutine for each feed to find the results. for _, feed := range feeds { // Retrieve a matcher for the search. matcher, exists := matchers[feed.Type] if !exists { matcher = matchers[\"default\"] } // Launch the goroutine to perform the search. go func(matcher Matcher, feed *Feed) { Match(matcher, feed, searchTerm, results) waitGroup.Done() }(matcher, feed) } // Launch a goroutine to monitor when all the work is done. go func() { // Wait for everything to be processed. waitGroup.Wait() // Close the channel to signal to the Display // function that we can exit the program. close(results) }() // Start displaying results as they are available and // return after the final result is displayed. Display(results)}// Register is called to register a matcher for use by the program.func Register(feedType string, matcher Matcher) { if _, exists := matchers[feedType]; exists { log.Fatalln(feedType, \"Matcher already registered\") } log.Println(\"Register\", feedType, \"matcher\") matchers[feedType] = matcher} 对于上面代码，有以下问题需要明确下： feeds, err := RetrieveFeeds() 这种一个函数返回两个值，第一个参数返回值，第二个返回错误信息，是GO中常用的模式 声明运算符（:=），这个运算符在声明变量的同时，给变量赋值 feeds 是一个切片，可以理解为Go里面的动态数组，是一种引用类型 results是一个无缓冲的channel，和map、slice一样，都是引用类型，channel内置同步机制，从而保证通信安全 Go中，如果main函数返回，整个程序也就终止了，终止时，会关闭所有之前启动而且还在运行的goroutine for range对feeds切片做迭代，和python里面的 for in一样的道理，每次迭代会返回两个值（index，value），value是一个副本，下划线_是一个占位符 使用go关键字启动一个goroutine，并对这个goroutine做并发调度。上面程序中go启动了一个匿名函数作为goroutine 在Go语言中，所有的变量都是以值的方式传递。所以想要修改真正的值，可以传递指针 Go语言支持闭包，匿名函数中访问searchTerm、results就是通过闭包的形势访问的。注意matcher、feed这两个变量并没有使用闭包的形式访问 2.3.2 feed.gofeed会从本地的data/data.json中读取Json数据，并将数据反序列化为feed切片,defer会安排随后的函数调用在函数返回时才执行, 使用defer可以缩短打开文件和关闭文件的代码间隔 123456789101112131415161718192021222324252627282930313233343536package searchimport ( \"encoding/json\" \"os\")const dataFile = \"data/data.json\"// Feed contains information we need to process a feed.type Feed struct { Name string `json:\"site\"` URI string `json:\"link\"` Type string `json:\"type\"`}// RetrieveFeeds reads and unmarshals the feed data file.func RetrieveFeeds() ([]*Feed, error) { // Open the file. file, err := os.Open(dataFile) if err != nil { return nil, err } // Schedule the file to be closed once // the function returns. defer file.Close() // Decode the file into a slice of pointers // to Feed values. var feeds []*Feed err = json.NewDecoder(file).Decode(&amp;feeds) // We don't need to check for errors, the caller can do this. return feeds, err} 2.3.3 match.go/default.go123456789101112131415package search// defaultMatcher implements the default matcher.type defaultMatcher struct{}// init registers the default matcher with the program.func init() { var matcher defaultMatcher Register(\"default\", matcher)}// Search implements the behavior for the default matcher.func (m defaultMatcher) Search(feed *Feed, searchTerm string) ([]*Result, error) { return nil, nil} func (m defaultMatcher) Search 意味着search和defaultMatcher的值绑定在了一起，我们可以使用defaultMatcher 类型的值或者指向这个类型值的指针来调用Search 方法。无论我们是使用接收者类型的值来调用这个方，还是使用接收者类型值的指针来调用这个方法，编译器都会正确地引用或者解引用对应的值，作为接收者传递给Search 方法 123456789101112// 方法声明为使用defaultMatcher 类型的值作为接收者func (m defaultMatcher) Search(feed *Feed, searchTerm string)// 声明一个指向defaultMatcher 类型值的指针dm := new(defaultMatch)// 编译器会解开dm 指针的引用，使用对应的值调用方法dm.Search(feed, \"test\")// 方法声明为使用指向defaultMatcher 类型值的指针作为接收者func (m *defaultMatcher) Search(feed *Feed, searchTerm string)// 声明一个defaultMatcher 类型的值var dm defaultMatch// 编译器会自动生成指针引用dm 值，使用指针调用方法dm.Search(feed, \"test\") 与直接通过值或者指针调用方法不同，如果通过接口类型的值调用方法，规则有很大不同，如代码清单2-38 所示。使用指针作为接收者声明的方法，只能在接口类型的值是一个指针的时候被调用。使用值作为接收者声明的方法，在接口类型的值为值或者指针时，都可以被调用。12345678910111213141516// 方法声明为使用指向defaultMatcher 类型值的指针作为接收者func (m *defaultMatcher) Search(feed *Feed, searchTerm string)// 通过interface 类型的值来调用方法var dm defaultMatchervar matcher Matcher = dm // 将值赋值给接口类型matcher.Search(feed, \"test\") // 使用值来调用接口方法&gt; go buildcannot use dm (type defaultMatcher) as type Matcher in assignment// 方法声明为使用defaultMatcher 类型的值作为接收者func (m defaultMatcher) Search(feed *Feed, searchTerm string)// 通过interface 类型的值来调用方法var dm defaultMatchervar matcher Matcher = &amp;dm // 将指针赋值给接口类型matcher.Search(feed, \"test\") // 使用指针来调用接口方法&gt; go buildBuild Successful match创建不同类型的匹配器，Matcher其实是一个接口，对于每种匹配器又有不同的具体实现。下面的代码中，Matcher接口定义了一个Search方法，每个实现了Search方法的类型都实现了Matcher接口 12345678910111213141516171819202122232425262728293031323334353637383940414243package searchimport ( \"log\")// Result contains the result of a search.type Result struct { Field string Content string}// Matcher defines the behavior required by types that want// to implement a new search type.type Matcher interface { Search(feed *Feed, searchTerm string) ([]*Result, error)}// Match is launched as a goroutine for each individual feed to run// searches concurrently.func Match(matcher Matcher, feed *Feed, searchTerm string, results chan&lt;- *Result) { // Perform the search against the specified matcher. searchResults, err := matcher.Search(feed, searchTerm) if err != nil { log.Println(err) return } // Write the results to the channel. for _, result := range searchResults { results &lt;- result }}// Display writes results to the console window as they// are received by the individual goroutines.func Display(results chan *Result) { // The channel blocks until a result is written to the channel. // Once the channel is closed the for loop terminates. for result := range results { log.Printf(\"%s:\\n%s\\n\\n\", result.Field, result.Content) }} Display方法会迭代results这个channel，有数据时会打印，没数据时会阻塞，当main.go中的close(result)后，for range循环结束 注意到default.go有init函数，这个函数会在main中通过下划线导入包的时候执行，init的功能是初始化匹配器 2.4 RSS 匹配器rss.go篇幅过长，这里不贴代码了，其中有几个关注的点说下：在init中注册了一个rssMatcher，这个match和之前的defaultMatcher一样，绑定了Search方法，即实现了Matcher接口1234func init() { var matcher rssMatcher search.Register(\"rss\", matcher)} rss.go主要有两个方法retrieve和Search，retrieve负责抓取网略资源，search负责匹配，具体匹配方法这里不表了 2.5 小结 每个代码文件都属于一个包，而包名应该与代码文件所在的文件夹同名。 Go 语言提供了多种声明和初始化变量的方式。如果变量的值没有显式初始化，编译器会将变量初始化为零值。 使用指针可以在函数间或者goroutine 间共享数据。 通过启动goroutine 和使用通道完成并发和同步。 Go 语言提供了内置函数来支持Go 语言内部的数据结构。 标准库包含很多包，能做很多很有用的事情。 使用Go 接口可以编写通用的代码和框架。","link":"/2019/04/11/go_quick_prog/"},{"title":"一个线程安全的单例模式","text":"单例模式的一般构造方法 123456789101112131415public class SingletonConsumer { private final static Logger logger = Logger.getLogger(SingletonConsumer.class); private static SingletonConsumer instance; private SingletonConsumer() { } public SingletonConsumer getInstance() { if (instance == null) { logger.debug(\"instance is null, trying to instantiate a new one\"); instance = new SingletonConsumer(); } else { logger.debug(\"instance is not null, return the already-instantiated one\"); } return instance; }} 以上这种构造方法在单线程下运行是安全的，但是如果放到多线程下，则会出现各种各样的问题，为此我们设计一个实验来验证多线程下，以上方法会出现什么问题。 Experiment实验中我们设置10个线程去创建SingletonConsumer实例，最后验证到底创建了多少个实例。 12345678910111213@Test public void singletonConsumerTest() throws InterruptedException { ExecutorService executors = Executors.newFixedThreadPool(10); Set&lt;SingletonConsumer&gt; set = new HashSet&lt;&gt;(); for(int i = 0; i &lt; 10; i++){ executors.execute( () -&gt; set.add(SingletonConsumer.getInstance()) ); } executors.shutdown(); executors.awaitTermination(1, TimeUnit.HOURS); Assert.assertEquals(10, set.size()); } 运行测试，输出结果如下 12345678910112017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new one2017-02-26 13:50:52 DEBUG SingletonConsumer:20 - instance is null, trying to instantiate a new oneset size:10 会发现此时实际上构造了是个SingletonConsumer实例，那怎么才能构造线程安全的单例模式？首先想到的方法是将getInstance的代码用synchronized包起来，这样就能够保证getInstance方法每次只能有一个线程访问到，于是代码就变成了下面的样子 1234567891011public static SingletonConsumer getInstance() { synchronized (SingletonConsumer.class) { if (instance == null) { logger.debug(\"instance is null, trying to instantiate a new one\"); instance = new SingletonConsumer(); } else { logger.debug(\"instance is not null, return the already-instantiated one\"); } return instance; } } 我们再次运行测试脚本 12345678910111213142017-02-26 14:01:12 DEBUG SingletonConsumer:21 - instance is null, trying to instantiate a new one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated one2017-02-26 14:01:12 DEBUG SingletonConsumer:24 - instance is not null, return the already-instantiated onejava.lang.AssertionError: Expected :10Actual :1 &lt;Click to see difference&gt; 此时发现，只初始化了一个SingletonConsumer实例，说明这种方法是work的。 但是仔细去想一想，上面的方法是有效率问题的。假设有一个线程A正在synchronized块中判断instance是否为null，此时其他线程只能等待线程A判断完毕才可以再去判断。仔细想想，instance是否为空，其实是可以多个线程同时去判断的，因此我们将代码修改成一下形式： 123456789if (instance == null) { synchronized (SingletonConsumer.class) { logger.debug(\"instance is null, trying to instantiate a new one\"); instance = new SingletonConsumer(); } } else { logger.debug(\"instance is not null, return the already-instantiated one\"); } return instance; 上面的代码中，我们将instance是否为空的判断移到了同步块的外面。那这种方法是否是线程安全的呢，再次运行测试脚本，观察结果： 12345678910112017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new one2017-02-26 14:14:18 DEBUG SingletonConsumer:28 - instance is null, trying to instantiate a new oneset size:10 通过结果发现，依然实例化了10个SingeltonCoumser。考虑一种情况，初始install为空，线程A判断完instance是否为空，发现instance为null，刚好线程A的时间片用完，轮到线程B去判断instance是否为空，线程B发现instance也是null，此时时间片又回到了线程A的手中，线程A去创建SingletonConsumer对象，创建完成，线程B去创建对象，这样下去，就造成了上述实验的现象，因此，未解决上面的问题，需要带同步块中同样去判断instance是否为null。最后的代码如下： 12345678910111213141516public static SingletonConsumer getInstance() { if (instance == null) { synchronized (SingletonConsumer.class) { if (instance == null) { logger.debug(\"instance is null, trying to instantiate a new one\"); instance = new SingletonConsumer(); } else { logger.debug(\"instance is not null, return the already-instantiated one \"); } } } else { logger.debug(\"instance is not null, return the already-instantiated one\"); } return instance; } 最有还有一点要注意，由于JVM会对代码进行优化，所以代码的执行顺序在真运行的时候会发生变化，会导致赋值操作编程不可见的，因此才进行赋值操作时，instance有可能只拿到一个为完全初始化的实例，这样会导致一些错误。 instance = new SingletonConsumer(); 解决办法是将instance生命为volatile的，volatile关键词可以保证可见性和有序性，其具体内容待下次再表。 Summary总之，一个线程安全的单例模式需要注意以下3点： 1.getInstance的需要用synchronized关键词 2.为提高效率，instance是否为空可提到同步块以外，但内层的判断依然要保留 3.instance需要声明为volatile 代码见：GitHub","link":"/2017/12/05/safe-singleton/"}],"tags":[{"name":"闭包","slug":"闭包","link":"/tags/闭包/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"装饰器","slug":"装饰器","link":"/tags/装饰器/"},{"name":"多线程","slug":"多线程","link":"/tags/多线程/"},{"name":"生产者消费者模型","slug":"生产者消费者模型","link":"/tags/生产者消费者模型/"},{"name":"单例模式","slug":"单例模式","link":"/tags/单例模式/"},{"name":"线程安全","slug":"线程安全","link":"/tags/线程安全/"}],"categories":[{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"Go In Action","slug":"Go-In-Action","link":"/categories/Go-In-Action/"},{"name":"java","slug":"java","link":"/categories/java/"}]}